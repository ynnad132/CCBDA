# -*- coding: utf-8 -*-
"""CycleGAN_v2.ipynb 的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oq7Gi-2r_8dkr2-V4_EctQHFbePzFMx-
"""


import os
import torch
from torch import nn, optim
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms
from torchvision.models import resnet18, ResNet18_Weights
from fastai.vision.models.unet import DynamicUnet

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

batch_size = 4
n_epoches = 100
decay_epoch = 20
lr = 0.0002
b1 = 0.5
b2 = 0.999
data_dir = os.getcwd()+''

# In[]

def build_res_unet(n_input=1, n_output=2, size=128):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)
    resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
    resnet.conv1 = nn.Conv2d(in_channels=n_input, out_channels=64, kernel_size=3, stride=1, padding=1,bias=False)
    resnet = nn.Sequential(*list(resnet.children())[:-2])
    net_G = DynamicUnet(resnet, n_output, (size, size)).to(device)
    return net_G

class Discriminator(nn.Module):
    def __init__(self, input_c, num_filters=64, n_down=3):
        super().__init__()
        model = [self.get_layers(input_c, num_filters, norm=False)]
        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) 
                          for i in range(n_down)] # the 'if' statement is taking care of not using
                                                  # stride of 2 for the last block in this loop
        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or
                                                                                             # activation for the last layer of the model
        self.model = nn.Sequential(*model)                                                   
        
    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,
        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose
        if norm: layers += [nn.BatchNorm2d(nf)]
        if act: layers += [nn.LeakyReLU(0.2, True)]
        return nn.Sequential(*layers)
    
    def forward(self, x):
        return self.model(x)

# In[]


class GANLoss(nn.Module):
    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):
        super().__init__()
        self.register_buffer('real_label', torch.tensor(real_label))
        self.register_buffer('fake_label', torch.tensor(fake_label))
        if gan_mode == 'vanilla':
            self.loss = nn.BCEWithLogitsLoss()
        elif gan_mode == 'lsgan':
            self.loss = nn.MSELoss()
    
    def get_labels(self, preds, target_is_real):
        if target_is_real:
            labels = self.real_label
        else:
            labels = self.fake_label
        return labels.expand_as(preds)
    
    def __call__(self, preds, target_is_real):
        labels = self.get_labels(preds, target_is_real)
        loss = self.loss(preds, labels)
        return loss

# In[]

criterion_GAN = GANLoss(gan_mode='lsgan') # nn.MSELoss()
criterion_cycle = nn.L1Loss()
criterion_identity = nn.L1Loss()

G_AB = build_res_unet(n_input=2, n_output=2, size=128)    # ab -> ab
D_B = Discriminator(input_c=2, n_down=3, num_filters=64)

G_BA = build_res_unet(n_input=2, n_output=2, size=128)    # ab -> ab
D_A = Discriminator(input_c=2, n_down=3, num_filters=64)

G_AB = G_AB.to(device)
D_B = D_B.to(device)
G_BA = G_BA.to(device)
D_A = D_A.to(device)
    
criterion_GAN = criterion_GAN.to(device)
criterion_cycle = criterion_cycle.to(device)
criterion_identity = criterion_identity.to(device)


# In[]

import itertools
optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1, b2))
optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(b1, b2))
optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(b1, b2))

lambda_func = lambda epoch: 1 - max(0, epoch-decay_epoch)/(n_epoches-decay_epoch)

lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_func)
lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_func)
lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_func)


# In[]

from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from skimage.color import rgb2lab, lab2rgb

class ImageDataset(Dataset):
    def __init__(self, data_dir, mode='train', size=128):
        self.mode = mode   
        A_dir = os.path.join(data_dir, 'real')
        B_dir = os.path.join(data_dir, 'hayao')    
        if mode == 'train':
            self.files_A = [os.path.join(A_dir, name) for name in sorted(os.listdir(A_dir))[:3000]]
            self.files_B = [os.path.join(B_dir, name) for name in sorted(os.listdir(B_dir))[:3000]]
            self.transforms = transforms.Compose([
                transforms.Resize((size, size)),
                transforms.RandomHorizontalFlip(),
            ])
        elif mode == 'test':
            self.files_A = [os.path.join(A_dir, name) for name in sorted(os.listdir(A_dir))[3000:3434]]
            self.files_B = [os.path.join(B_dir, name) for name in sorted(os.listdir(B_dir))[3000:]]
            self.transforms = transforms.Resize((size, size))
        
    def __len__(self):
        return len(self.files_A)
    
    def __getitem__(self, index):
        file_A = self.files_A[index]
        file_B = self.files_B[index]
        img_A, img_B = Image.open(file_A).convert("RGB"), Image.open(file_B).convert("RGB")
        img_A, img_B = self.transforms(img_A), self.transforms(img_B)
        img_A, img_B = np.array(img_A), np.array(img_B)
        img_A_lab = rgb2lab(img_A).astype("float32") # Converting RGB to L*a*b
        img_B_lab = rgb2lab(img_B).astype("float32") 
        img_A_lab = transforms.ToTensor()(img_A_lab)
        img_B_lab = transforms.ToTensor()(img_B_lab)
        A_L = img_A_lab[[0], ...] / 50. - 1. # Between -1 and 1
        A_ab = img_A_lab[[1, 2], ...] / 110. # Between -1 and 1
        B_L = img_B_lab[[0], ...] / 50. - 1. # Between -1 and 1
        B_ab = img_B_lab[[1, 2], ...] / 110. # Between -1 and 1        
        return A_L, A_ab, B_L, B_ab  # img_A, img_B

# In[]

trainloader = DataLoader(
    ImageDataset(data_dir, mode='train'),
    batch_size = batch_size,
    shuffle = True,
    num_workers = 0
)

testloader = DataLoader(
    ImageDataset(data_dir, mode='test'),
    batch_size = batch_size,
    shuffle = True,
    num_workers = 0
)

# In[]

def lab_to_rgb(L, ab):
    """
    Takes a batch of images
    """
    
    L = (L + 1.) * 50.
    ab = ab * 110.
    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()
    rgb_imgs = []
    for img in Lab:
        img_rgb = lab2rgb(img)
        rgb_imgs.append(img_rgb)
    return np.stack(rgb_imgs, axis=0)

# In[]

from torchvision.utils import make_grid

Tensor = torch.cuda.FloatTensor if (device=='cuda') else torch.Tensor

def sample_images(A_L, A_ab, B_L, B_ab,epoch, figside = 1.5):
    assert A_L.size() == B_L.size(), 'The image size for two domains must be the same'
    epoch = epoch+1
    G_AB.eval()
    G_BA.eval()
    
    A_L = A_L.type(Tensor).to(device)
    A_ab = A_ab.type(Tensor).to(device)
    fake_B_ab = G_AB(A_ab).detach()

    B_L = B_L.type(Tensor).to(device)
    B_ab = B_ab.type(Tensor).to(device)
    fake_A_ab = G_BA(B_ab).detach()

    fake_A = lab_to_rgb(A_L, fake_B_ab)
    real_A = lab_to_rgb(A_L, A_ab)
    fake_B = lab_to_rgb(B_L, fake_A_ab)
    real_B = lab_to_rgb(B_L, B_ab)

    fake_A = torch.Tensor(fake_A).permute(0, 3, 1, 2)
    real_A = torch.Tensor(real_A).permute(0, 3, 1, 2)
    fake_B = torch.Tensor(fake_B).permute(0, 3, 1, 2)
    real_B = torch.Tensor(real_B).permute(0, 3, 1, 2)

    real_A_row = make_grid(real_A[:5], nrow=5, normalize=True)
    fake_B_row = make_grid(fake_B[:5], nrow=5, normalize=True)
    real_B_row = make_grid(real_B[:5], nrow=5, normalize=True)
    fake_A_row = make_grid(fake_A[:5], nrow=5, normalize=True)

    image_grid = torch.cat((real_A_row, fake_A_row, real_B_row, fake_B_row), 1).cpu().permute(1, 2, 0)

    
    
    plt.figure(figsize=(figside*5, figside*4))
    plt.imshow(image_grid)
    plt.axis('off')
    plt.show()
    toPIL = transforms.ToPILImage()
    save_img = toPIL(image_grid.permute(2,0,1))
    save_img.save(f"epoch_{epoch}.jpg")

#%%
A_L, A_ab, B_L, B_ab = next(iter(testloader))
sample_images(A_L, A_ab, B_L, B_ab,0)




# In[]

from tqdm import tqdm

best_G_loss = 100
save_path_AB = os.getcwd() + '/model/CycleGAN_G_AB.pt'
save_path_BA = os.getcwd() + '/model/CycleGAN_G_BA.pt'

for epoch in range(n_epoches):
    for i, (A_L, A_ab, B_L, B_ab) in enumerate(tqdm(trainloader)):
        A_L, A_ab = A_L.type(Tensor).to(device), A_ab.type(Tensor).to(device)
        B_L, B_ab = B_L.type(Tensor).to(device), B_ab.type(Tensor).to(device)
        
        """Train Generators"""
        # set to training mode in the begining, beacause sample_images will set it to eval mode
        G_AB.train()
        G_BA.train()
        
        optimizer_G.zero_grad()
        
        fake_A_ab = G_AB(A_ab)   
        fake_B_ab = G_BA(B_ab)
        
        # identity loss
        loss_id_A = criterion_identity(fake_A_ab, A_ab)
        loss_id_B = criterion_identity(fake_B_ab, B_ab)
        loss_identity = (loss_id_A + loss_id_B) / 2
        
        # GAN loss, train G to make D think it's true
        loss_GAN_AB = criterion_GAN(D_B(fake_A_ab), True) 
        loss_GAN_BA = criterion_GAN(D_A(fake_B_ab), True)
        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2

        # cycle loss
        recov_A = G_BA(fake_A_ab)
        recov_B = G_AB(fake_B_ab)
        loss_cycle_A = criterion_cycle(recov_A, A_ab)
        loss_cycle_B = criterion_cycle(recov_B, B_ab)
        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2
        
        # G totol loss
        loss_G = 5.0*loss_identity + loss_GAN + 10.0*loss_cycle
        
        loss_G.backward()
        optimizer_G.step()
        
        """Train Discriminator A"""
        optimizer_D_A.zero_grad()
        
        loss_real = criterion_GAN(D_A(A_ab), True)
        loss_fake = criterion_GAN(D_A(fake_B_ab.detach()), False)
        loss_D_A = (loss_real + loss_fake) / 2
        
        loss_D_A.backward()
        optimizer_D_A.step()
        
        """Train Discriminator B"""
        optimizer_D_B.zero_grad()
        
        loss_real = criterion_GAN(D_B(B_ab), True)
        loss_fake = criterion_GAN(D_B(fake_A_ab.detach()), False)
        loss_D_B = (loss_real + loss_fake) / 2
        
        loss_D_B.backward()
        optimizer_D_B.step()
    
    lr_scheduler_G.step()
    lr_scheduler_D_A.step()
    lr_scheduler_D_B.step()
    
    # save model
    if loss_G.item() < best_G_loss:
        best_G_loss = loss_G.item()
        torch.save(G_AB.state_dict(), save_path_AB)
        torch.save(G_BA.state_dict(), save_path_BA)
        print('Save model.')
    
    # test
    if (epoch+1) % 5 == 0:
        test_A_L, test_A_ab, test_B_L, test_B_ab = next(iter(testloader))
        sample_images(test_A_L, test_A_ab, test_B_L, test_B_ab,epoch,figside = 1.5)

        loss_D = (loss_D_A + loss_D_B) / 2
        print(f'[Epoch {epoch+1}/{n_epoches}]')
        print(f'[G loss: {loss_G.item()} | identity: {loss_identity.item()} GAN: {loss_GAN.item()} cycle: {loss_cycle.item()}]')
        print(f'[D loss: {loss_D.item()} | D_A: {loss_D_A.item()} D_B: {loss_D_B.item()}]')
        
        
        



























